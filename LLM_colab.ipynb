{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV15fIB5Dx0HKMoCAUD4fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MridulaLakshmanan/LLM-colab/blob/main/LLM_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J3ufi28wh6t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "client = InferenceClient(api_key=userdata.get('HF_Token'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers accelerate bitsandbytes\n",
        "!pip install sentencepiece\n",
        "!pip install langdetect\n",
        "!pip install translate"
      ],
      "metadata": {
        "id": "zzzp3upk4Dsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"who is the father of nation india?\"}],\n",
        "    model=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "#    model=\"Hemanth-thunder/Tamil-Mistral-7B-Instruct-v0.1\"\n",
        ")\n",
        "\n",
        "print(completion.choices)"
      ],
      "metadata": {
        "id": "NY7doPzn0jnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion1 = client.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"who is the father of nation india?\"}],\n",
        "    model=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        ")\n",
        "\n",
        "print(completion1.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "GKPEVn5K4YLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion2 = client.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"who is the father of nation india?\"}],\n",
        "    model=\"meta-llama/Llama-3.2-3B-Instruct\" # Changed to a chat-compatible model\n",
        ")\n",
        "print(completion2.choices[0].message.content)"
      ],
      "metadata": {
        "id": "t3C_dGpM4s6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = client.text_to_image(\n",
        "    prompt=\"picture of biriyani\",\n",
        "    model=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        ")\n",
        "\n",
        "# Save the generated image\n",
        "image.save(\"generated_image.png\")"
      ],
      "metadata": {
        "id": "PjoLXklf5sox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = client.text_to_image(\n",
        "    prompt=\"a girl sitting and watching a sunset in a beach\",\n",
        "    model=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        ")\n",
        "\n",
        "# Save the generated image\n",
        "image.save(\"generated_image2.png\")"
      ],
      "metadata": {
        "id": "9_RAmUux6dSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Authenticate with Hugging Face for gated models\n",
        "# Make sure you have accepted the terms and conditions for this model on Hugging Face\n",
        "login(token=userdata.get('HF_Token'))\n",
        "\n",
        "model_id = \"CoRover/BharatGPT-3B-Indic\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who responds in Tamil\"},\n",
        "    {\"role\": \"user\", \"content\": \"நீ யார்?\"},\n",
        "]\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        ")\n",
        "print(outputs[0][\"generated_text\"][-1])"
      ],
      "metadata": {
        "id": "ehIFucNmLtKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}